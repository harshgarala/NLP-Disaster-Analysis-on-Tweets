{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset and apply data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset used in this example is taken from Twitter. Various NLP methods and Sentimental Analysis methods has been carried out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from autocorrect import spell\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns from dataset\n",
    "ds.drop([\"id\", \"keyword\"], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters in text column of dataset\n",
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
    "for char in spec_chars:\n",
    "    ds['text'] = ds['text'].str.replace(char, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply word tokanization in text column of dataset\n",
    "ds['tokenized_sents'] = ds.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop-words from the text column of dataset\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words1 = [x for x in stop_words if \"n'\" not in x] \n",
    "stop_words2 = [x for x in stop_words1 if x not in ('against','aren','after','no','nor','not','only','too','very','haven','couldn','didn','doesn','hadn','hasn','haven','isn','ma','mightn','mustn','needn','shan','shouldn','wasn','weren','won','wouldn')]\n",
    "ds['stopwords_sents'] = ds['tokenized_sents'].apply(lambda x: [item for item in x if item.lower() not in stop_words2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming \n",
    "stemming = PorterStemmer()\n",
    "ds['stemming'] = ds['stopwords_sents'].apply(lambda x: [stemming.stem(item) for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "ds['lemmatizer'] = ds['stopwords_sents'].apply(lambda x: [lemmatizer.lemmatize(item, pos ='v') for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autocorrect\n",
    "def autocorrect_spell(row):\n",
    "    hg= row['processed']\n",
    "    g=[]\n",
    "    #g=(str(' '.join([spell(word) for word in hg])))\n",
    "    g.append(spell(str(hg))) \n",
    "    return g\n",
    "ds['corrected_speller'] = ds.apply(autocorrect_spell, axis=1)\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def autocorrect_tx(row):\n",
    "    hg= row['processed']\n",
    "    g=[]\n",
    "    #for word in hg:\n",
    "    g.append(str(TextBlob(str(hg)).correct()))\n",
    "    return g\n",
    "ds['corrected_textblob'] = ds.apply(autocorrect_tx, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get City,State, and Country from Location field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locationtagger\n",
    "#data2.to_csv(r'country.csv')\n",
    "def loc(row):\n",
    "    hg_list = row['location']\n",
    "    entities = locationtagger.find_locations(text = hg_list)\n",
    "    return (entities.countries)\n",
    "\n",
    "ds['country'] = ds.apply(loc, axis=1)\n",
    "def loc(row):\n",
    "    hg_list = row['location']\n",
    "    entities = locationtagger.find_locations(text = hg_list)\n",
    "    return (entities.cities)\n",
    "\n",
    "ds['city'] = ds.apply(loc, axis=1)\n",
    "def loc(row):\n",
    "    hg_list = row['location']\n",
    "    entities = locationtagger.find_locations(text = hg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sentence from words\n",
    "def rejoin_words(row):\n",
    "    my_list = row['corrected_textblob']\n",
    "    joined_words = (\" \".join(my_list))\n",
    "    return joined_words\n",
    "ds['new_text'] = ds.apply(rejoin_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle a text column's rows\n",
    "ds = ds.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>stopwords_sents</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>TheJenMorillo GM  I pray any attack of the en...</td>\n",
       "      <td>0</td>\n",
       "      <td>[TheJenMorillo, GM, I, pray, any, attack, of, ...</td>\n",
       "      <td>[TheJenMorillo, GM, pray, attack, enemy, 2, de...</td>\n",
       "      <td>[thejenmorillo, gm, pray, attack, enemi, 2, de...</td>\n",
       "      <td>[TheJenMorillo, GM, pray, attack, enemy, 2, de...</td>\n",
       "      <td>TheJenMorillo GM pray attack enemy 2 derail ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>My portable closet has collapsed 3x and it fin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[My, portable, closet, has, collapsed, 3x, and...</td>\n",
       "      <td>[portable, closet, collapsed, 3x, finally, bro...</td>\n",
       "      <td>[portabl, closet, collaps, 3x, final, broke, m...</td>\n",
       "      <td>[portable, closet, collapse, 3x, finally, brea...</td>\n",
       "      <td>portable closet collapse 3x finally break mom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>newyorkcity for the  international emergency ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[newyorkcity, for, the, international, emergen...</td>\n",
       "      <td>[newyorkcity, international, emergency, medici...</td>\n",
       "      <td>[newyorkc, intern, emerg, medicin, confer, w, ...</td>\n",
       "      <td>[newyorkcity, international, emergency, medici...</td>\n",
       "      <td>newyorkcity international emergency medicine c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>Don t Panik   KelbyTomlinson to the rescue  ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Don, t, Panik, KelbyTomlinson, to, the, rescu...</td>\n",
       "      <td>[Panik, KelbyTomlinson, rescue, http, co, hujv...</td>\n",
       "      <td>[panik, kelbytomlinson, rescu, http, co, hujvg...</td>\n",
       "      <td>[Panik, KelbyTomlinson, rescue, http, co, hujv...</td>\n",
       "      <td>Panik KelbyTomlinson rescue http co hujvgsFLUs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>NaturalDisasters As California fires rage the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[NaturalDisasters, As, California, fires, rage...</td>\n",
       "      <td>[NaturalDisasters, California, fires, rage, Fo...</td>\n",
       "      <td>[naturaldisast, california, fire, rage, forest...</td>\n",
       "      <td>[NaturalDisasters, California, fire, rage, For...</td>\n",
       "      <td>NaturalDisasters California fire rage Forest S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>Obama Declares Disaster for Typhoon Devastated...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Obama, Declares, Disaster, for, Typhoon, Deva...</td>\n",
       "      <td>[Obama, Declares, Disaster, Typhoon, Devastate...</td>\n",
       "      <td>[obama, declar, disast, typhoon, devast, saipa...</td>\n",
       "      <td>[Obama, Declares, Disaster, Typhoon, Devastate...</td>\n",
       "      <td>Obama Declares Disaster Typhoon Devastated Sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>screams  http   t co PU7C4Hhbxj</td>\n",
       "      <td>0</td>\n",
       "      <td>[screams, http, t, co, PU7C4Hhbxj]</td>\n",
       "      <td>[screams, http, co, PU7C4Hhbxj]</td>\n",
       "      <td>[scream, http, co, pu7c4hhbxj]</td>\n",
       "      <td>[scream, http, co, PU7C4Hhbxj]</td>\n",
       "      <td>scream http co PU7C4Hhbxj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Experts in France begin examining airplane deb...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Experts, in, France, begin, examining, airpla...</td>\n",
       "      <td>[Experts, France, begin, examining, airplane, ...</td>\n",
       "      <td>[expert, franc, begin, examin, airplan, debri,...</td>\n",
       "      <td>[Experts, France, begin, examine, airplane, de...</td>\n",
       "      <td>Experts France begin examine airplane debris f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>Drunk Meals 101  What To Cook When You re Tota...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Drunk, Meals, 101, What, To, Cook, When, You,...</td>\n",
       "      <td>[Drunk, Meals, 101, Cook, Totally, Obliterated...</td>\n",
       "      <td>[drunk, meal, 101, cook, total, obliter, http,...</td>\n",
       "      <td>[Drunk, Meals, 101, Cook, Totally, Obliterated...</td>\n",
       "      <td>Drunk Meals 101 Cook Totally Obliterated http ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>CTD arrest three vital criminals from Orangi  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CTD, arrest, three, vital, criminals, from, O...</td>\n",
       "      <td>[CTD, arrest, three, vital, criminals, Orangi,...</td>\n",
       "      <td>[ctd, arrest, three, vital, crimin, orangi, ka...</td>\n",
       "      <td>[CTD, arrest, three, vital, criminals, Orangi,...</td>\n",
       "      <td>CTD arrest three vital criminals Orangi KARACH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "2380   TheJenMorillo GM  I pray any attack of the en...       0   \n",
       "1651  My portable closet has collapsed 3x and it fin...       0   \n",
       "3142   newyorkcity for the  international emergency ...       0   \n",
       "5650  Don t Panik   KelbyTomlinson to the rescue  ht...       0   \n",
       "4040   NaturalDisasters As California fires rage the...       1   \n",
       "2739  Obama Declares Disaster for Typhoon Devastated...       1   \n",
       "5988                    screams  http   t co PU7C4Hhbxj       0   \n",
       "136   Experts in France begin examining airplane deb...       1   \n",
       "5208  Drunk Meals 101  What To Cook When You re Tota...       0   \n",
       "6605  CTD arrest three vital criminals from Orangi  ...       1   \n",
       "\n",
       "                                        tokenized_sents  \\\n",
       "2380  [TheJenMorillo, GM, I, pray, any, attack, of, ...   \n",
       "1651  [My, portable, closet, has, collapsed, 3x, and...   \n",
       "3142  [newyorkcity, for, the, international, emergen...   \n",
       "5650  [Don, t, Panik, KelbyTomlinson, to, the, rescu...   \n",
       "4040  [NaturalDisasters, As, California, fires, rage...   \n",
       "2739  [Obama, Declares, Disaster, for, Typhoon, Deva...   \n",
       "5988                 [screams, http, t, co, PU7C4Hhbxj]   \n",
       "136   [Experts, in, France, begin, examining, airpla...   \n",
       "5208  [Drunk, Meals, 101, What, To, Cook, When, You,...   \n",
       "6605  [CTD, arrest, three, vital, criminals, from, O...   \n",
       "\n",
       "                                        stopwords_sents  \\\n",
       "2380  [TheJenMorillo, GM, pray, attack, enemy, 2, de...   \n",
       "1651  [portable, closet, collapsed, 3x, finally, bro...   \n",
       "3142  [newyorkcity, international, emergency, medici...   \n",
       "5650  [Panik, KelbyTomlinson, rescue, http, co, hujv...   \n",
       "4040  [NaturalDisasters, California, fires, rage, Fo...   \n",
       "2739  [Obama, Declares, Disaster, Typhoon, Devastate...   \n",
       "5988                    [screams, http, co, PU7C4Hhbxj]   \n",
       "136   [Experts, France, begin, examining, airplane, ...   \n",
       "5208  [Drunk, Meals, 101, Cook, Totally, Obliterated...   \n",
       "6605  [CTD, arrest, three, vital, criminals, Orangi,...   \n",
       "\n",
       "                                               stemming  \\\n",
       "2380  [thejenmorillo, gm, pray, attack, enemi, 2, de...   \n",
       "1651  [portabl, closet, collaps, 3x, final, broke, m...   \n",
       "3142  [newyorkc, intern, emerg, medicin, confer, w, ...   \n",
       "5650  [panik, kelbytomlinson, rescu, http, co, hujvg...   \n",
       "4040  [naturaldisast, california, fire, rage, forest...   \n",
       "2739  [obama, declar, disast, typhoon, devast, saipa...   \n",
       "5988                     [scream, http, co, pu7c4hhbxj]   \n",
       "136   [expert, franc, begin, examin, airplan, debri,...   \n",
       "5208  [drunk, meal, 101, cook, total, obliter, http,...   \n",
       "6605  [ctd, arrest, three, vital, crimin, orangi, ka...   \n",
       "\n",
       "                                             lemmatizer  \\\n",
       "2380  [TheJenMorillo, GM, pray, attack, enemy, 2, de...   \n",
       "1651  [portable, closet, collapse, 3x, finally, brea...   \n",
       "3142  [newyorkcity, international, emergency, medici...   \n",
       "5650  [Panik, KelbyTomlinson, rescue, http, co, hujv...   \n",
       "4040  [NaturalDisasters, California, fire, rage, For...   \n",
       "2739  [Obama, Declares, Disaster, Typhoon, Devastate...   \n",
       "5988                     [scream, http, co, PU7C4Hhbxj]   \n",
       "136   [Experts, France, begin, examine, airplane, de...   \n",
       "5208  [Drunk, Meals, 101, Cook, Totally, Obliterated...   \n",
       "6605  [CTD, arrest, three, vital, criminals, Orangi,...   \n",
       "\n",
       "                                               new_text  \n",
       "2380  TheJenMorillo GM pray attack enemy 2 derail ur...  \n",
       "1651  portable closet collapse 3x finally break mom ...  \n",
       "3142  newyorkcity international emergency medicine c...  \n",
       "5650     Panik KelbyTomlinson rescue http co hujvgsFLUs  \n",
       "4040  NaturalDisasters California fire rage Forest S...  \n",
       "2739  Obama Declares Disaster Typhoon Devastated Sai...  \n",
       "5988                          scream http co PU7C4Hhbxj  \n",
       "136   Experts France begin examine airplane debris f...  \n",
       "5208  Drunk Meals 101 Cook Totally Obliterated http ...  \n",
       "6605  CTD arrest three vital criminals Orangi KARACH...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply various models for train dataset and find best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#set x as an independent veriable and y as a dependent variable\n",
    "x = ds[\"new_text\"]\n",
    "y = ds[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization using TfidfVectorizer\n",
    "#vectorization = TfidfVectorizer()\n",
    "\n",
    "#Vectorization using CountVectorizer\n",
    "vectorization = CountVectorizer() \n",
    "\n",
    "#Vectorization using HashingVectorizer\n",
    "#vectorization = HashingVectorizer() \n",
    "\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7946584938704028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83      1310\n",
      "           1       0.78      0.72      0.75       974\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.79      0.78      0.79      2284\n",
      "weighted avg       0.79      0.79      0.79      2284\n",
      "\n",
      "[[1115  195]\n",
      " [ 274  700]]\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)\n",
    "\n",
    "LR.score(xv_test, y_test)\n",
    "print(LR.score(xv_test, y_test))\n",
    "\n",
    "pred_LR = LR.predict(xv_test)\n",
    "print(classification_report(y_test, pred_LR))\n",
    "\n",
    "print(confusion_matrix(y_test, pred_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7535026269702276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79      1310\n",
      "           1       0.73      0.67      0.70       974\n",
      "\n",
      "    accuracy                           0.75      2284\n",
      "   macro avg       0.75      0.74      0.74      2284\n",
      "weighted avg       0.75      0.75      0.75      2284\n",
      "\n",
      "[[1070  240]\n",
      " [ 323  651]]\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train, y_train)\n",
    "\n",
    "DT.score(xv_test, y_test)\n",
    "print(DT.score(xv_test, y_test))\n",
    "\n",
    "pred_DT = DT.predict(xv_test)\n",
    "print(classification_report(y_test, pred_DT))\n",
    "\n",
    "print(confusion_matrix(y_test, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gardient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539404553415061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81      1310\n",
      "           1       0.81      0.55      0.66       974\n",
      "\n",
      "    accuracy                           0.75      2284\n",
      "   macro avg       0.77      0.73      0.73      2284\n",
      "weighted avg       0.76      0.75      0.74      2284\n",
      "\n",
      "[[1185  125]\n",
      " [ 437  537]]\n"
     ]
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(xv_train, y_train)\n",
    "\n",
    "GBC.score(xv_test, y_test)\n",
    "print(GBC.score(xv_test, y_test))\n",
    "\n",
    "pred_GBC = GBC.predict(xv_test)\n",
    "print(classification_report(y_test, pred_GBC))\n",
    "\n",
    "print(confusion_matrix(y_test, pred_GBC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859019264448336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83      1310\n",
      "           1       0.86      0.60      0.70       974\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.81      0.76      0.77      2284\n",
      "weighted avg       0.80      0.79      0.78      2284\n",
      "\n",
      "[[1215   95]\n",
      " [ 394  580]]\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(xv_train, y_train)\n",
    "\n",
    "RFC.score(xv_test, y_test)\n",
    "print(RFC.score(xv_test, y_test))\n",
    "\n",
    "pred_RFC = RFC.predict(xv_test)\n",
    "print(classification_report(y_test, pred_RFC))\n",
    "\n",
    "print(confusion_matrix(y_test, pred_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_label(n):\n",
    "    if n==0:\n",
    "        return \"Fake Disaster\"\n",
    "    elif n==1:\n",
    "        return \"True Disaster\"\n",
    "    \n",
    "def manual_testing(tweet):\n",
    "    testing_tweet = {\"text\":[tweet]}\n",
    "    new_def_test = pd.DataFrame(testing_tweet)\n",
    "    new_def_test[\"text\"] = new_def_test[\"text\"]\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_DT = DT.predict(new_xv_test)\n",
    "    pred_GBC = GBC.predict(new_xv_test)\n",
    "    pred_RFC = RFC.predict(new_xv_test)\n",
    "    \n",
    "    return print(\"\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(result_label(pred_LR[0]), \n",
    "                                                                                                              result_label(pred_DT[0]), \n",
    "                                                                                                              result_label(pred_GBC[0]), \n",
    "                                                                                                              result_label(pred_RFC[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = str(input())\n",
    "manual_testing(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize = vectorization.transform(df[\"text\"])\n",
    "new_vect = vectorization.fit_transform(df[\"text\"])\n",
    "df[\"pred\"]=LR.predict(new_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#df= pd.read_csv(\"test.csv\")\n",
    "\n",
    "#text = df[\"text\"]\n",
    "#new_vect = vectorization.fit_transform(text)\n",
    "#df[\"pred\"]=LR.predict(new_vect)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4159  183]\n",
      " [ 440 2831]]\n"
     ]
    }
   ],
   "source": [
    "#xv_train = vectorization.fit_transform(ds[\"new_text\"])\n",
    "vectorize = vectorization.transform(ds[\"new_text\"])\n",
    "_new = vectorization.fit_transform(ds[\"new_text\"])\n",
    "pred=LR.predict(vectorize)\n",
    "_t = ds[\"target\"]\n",
    "print(confusion_matrix(_t, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'y_Actual':    ds[\"target\"],\n",
    "        'y_Predicted': pred\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
